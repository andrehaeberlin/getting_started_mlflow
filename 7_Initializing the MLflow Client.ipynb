{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the MLflow Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on where you are running this notebook, your configuration may vary for how you initialize the MLflow Client in the following cell.\n",
    "\n",
    "For this example, we’re using a locally running tracking server, but other options are available (The easiest is to use the free managed service within Databricks Community Edition).\n",
    "\n",
    "Please see the guide to running notebooks here for more information on setting the tracking server uri and configuring access to either managed or self-managed MLflow tracking servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: review the links mentioned above for guidance on connecting to a managed tracking server, such as the free Databricks Community Edition\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Experiments with the MLflow Client API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at the Default Experiment that is created for us.\n",
    "\n",
    "This safe ‘fallback’ experiment will store Runs that we create if we don’t specify a new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/665823732664597081', creation_time=1707855087841, experiment_id='665823732664597081', last_update_time=1707855087841, lifecycle_stage='active', name='MLflow Quickstart', tags={}>, <Experiment: artifact_location='mlflow-artifacts:/232886580622657502', creation_time=1707574559267, experiment_id='232886580622657502', last_update_time=1707574559267, lifecycle_stage='active', name='Apple_Models', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
      "                        'experiment contains the produce models for apples.',\n",
      " 'project_name': 'grocery-forecasting',\n",
      " 'project_quarter': 'Q3-2023',\n",
      " 'store_dept': 'produce',\n",
      " 'team': 'stores-ml'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1707574453804, experiment_id='0', last_update_time=1707574453804, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "# Search experiments without providing query terms behaves effectively as a 'list' action\n",
    "\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<Experiment: artifact_location='./mlruns/0', creation_time=None, experiment_id='0', last_update_time=None, lifecycle_stage='active', name='Default', tags={}>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifecycle_stage': 'active', 'name': 'Default'}\n"
     ]
    }
   ],
   "source": [
    "# Extract the experiment name and lifecycle_stage\n",
    "\n",
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'lifecycle_stage': 'active', 'name': 'Default'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new Experiment\n",
    "In this section, we’ll:\n",
    "\n",
    "create a new MLflow Experiment\n",
    "\n",
    "apply metadata in the form of Experiment Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Experiment 'Apple_Models' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment_description \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the grocery forecasting project. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis experiment contains the produce models for apples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m experiment_tags \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrocery-forecasting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_dept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduce\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow.note.content\u001b[39m\u001b[38;5;124m\"\u001b[39m: experiment_description,\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m produce_apples_experiment \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mApple_Models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_tags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Use search_experiments() to search on the project_name tag key\u001b[39;00m\n\u001b[1;32m     18\u001b[0m apples_experiment \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msearch_experiments(\n\u001b[1;32m     19\u001b[0m     filter_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags.`project_name` = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrocery-forecasting\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m~/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/client.py:570\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    525\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    526\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m    :param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:235\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m:param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m:return: Integer ID of the created experiment.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mExperimentTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:98\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m     94\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     95\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m     96\u001b[0m     CreateExperiment(name\u001b[38;5;241m=\u001b[39mname, artifact_location\u001b[38;5;241m=\u001b[39martifact_location, tags\u001b[38;5;241m=\u001b[39mtag_protos)\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateExperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mexperiment_id\n",
      "File \u001b[0;32m~/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:220\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    218\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    219\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 220\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    222\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:152\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Experiment 'Apple_Models' already exists."
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_description = (\n",
    "    \"This is the grocery forecasting project. \"\n",
    "    \"This experiment contains the produce models for apples.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"grocery-forecasting\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "produce_apples_experiment = client.create_experiment(name=\"Apple_Models\", tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='mlflow-artifacts:/232886580622657502', creation_time=1707574559267, experiment_id='232886580622657502', last_update_time=1707574559267, lifecycle_stage='active', name='Apple_Models', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
      "                        'experiment contains the produce models for apples.',\n",
      " 'project_name': 'grocery-forecasting',\n",
      " 'project_quarter': 'Q3-2023',\n",
      " 'store_dept': 'produce',\n",
      " 'team': 'stores-ml'}>\n"
     ]
    }
   ],
   "source": [
    "# Use search_experiments() to search on the project_name tag key\n",
    "\n",
    "apples_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'grocery-forecasting'\"\n",
    ")\n",
    "\n",
    "pprint(apples_experiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Experiment: artifact_location='mlflow-artifacts:/977454266300166282', creation_time=1696346036899, experiment_id='977454266300166282', last_update_time=1696346036899, lifecycle_stage='active', name='Apple_Models', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
    "                        'experiment contains the produce models for apples.',\n",
    " 'project_name': 'grocery-forecasting',\n",
    " 'project_quarter': 'Q3-2023',\n",
    " 'store_dept': 'produce',\n",
    " 'team': 'stores-ml'}>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores-ml\n"
     ]
    }
   ],
   "source": [
    "# Access individual tag data\n",
    "\n",
    "print(apples_experiment[0].tags[\"team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stores-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running our first model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we’ll:\n",
    "\n",
    "* create a synthetic data set that is relevant to a simple demand forecasting task\n",
    "\n",
    "* start an MLflow run\n",
    "\n",
    "* log metrics, parameters, and tags to the run\n",
    "\n",
    "* save the model to the run\n",
    "\n",
    "* register the model during model logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data generator for demand of apples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that this is purely for demonstration purposes.\n",
    "\n",
    "The demand value is purely artificial and is deliberately covariant with the features. This is not a particularly realistic real-world scenario (if it were, we wouldn’t need Data Scientists!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29513/2690355518.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"previous_days_demand\"].fillna(method=\"bfill\", inplace=True)  # fill the first row\n",
      "/tmp/ipykernel_29513/2690355518.py:84: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[\"previous_days_demand\"].fillna(method=\"bfill\", inplace=True)  # fill the first row\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>price_per_kg</th>\n",
       "      <th>promo</th>\n",
       "      <th>demand</th>\n",
       "      <th>previous_days_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2024-01-25 17:18:05.062708</td>\n",
       "      <td>34.130183</td>\n",
       "      <td>1.454065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449177</td>\n",
       "      <td>0</td>\n",
       "      <td>999.306290</td>\n",
       "      <td>1029.418398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2024-01-26 17:18:05.062707</td>\n",
       "      <td>32.353643</td>\n",
       "      <td>9.462859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.856503</td>\n",
       "      <td>0</td>\n",
       "      <td>842.129427</td>\n",
       "      <td>999.306290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2024-01-27 17:18:05.062707</td>\n",
       "      <td>18.816833</td>\n",
       "      <td>0.391470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.326429</td>\n",
       "      <td>0</td>\n",
       "      <td>1317.616709</td>\n",
       "      <td>842.129427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2024-01-28 17:18:05.062706</td>\n",
       "      <td>34.533012</td>\n",
       "      <td>2.120477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>0</td>\n",
       "      <td>1395.802075</td>\n",
       "      <td>1317.616709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2024-01-29 17:18:05.062705</td>\n",
       "      <td>23.057202</td>\n",
       "      <td>2.365705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049931</td>\n",
       "      <td>0</td>\n",
       "      <td>1019.486305</td>\n",
       "      <td>1395.802075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2024-01-30 17:18:05.062704</td>\n",
       "      <td>34.810165</td>\n",
       "      <td>3.089005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.035149</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.564672</td>\n",
       "      <td>1019.486305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2024-01-31 17:18:05.062704</td>\n",
       "      <td>29.208905</td>\n",
       "      <td>3.673292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.518098</td>\n",
       "      <td>0</td>\n",
       "      <td>1086.143402</td>\n",
       "      <td>1002.564672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2024-02-01 17:18:05.062703</td>\n",
       "      <td>16.428676</td>\n",
       "      <td>4.077782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.268979</td>\n",
       "      <td>0</td>\n",
       "      <td>1093.207186</td>\n",
       "      <td>1086.143402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2024-02-02 17:18:05.062702</td>\n",
       "      <td>32.067512</td>\n",
       "      <td>2.734454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762317</td>\n",
       "      <td>0</td>\n",
       "      <td>1069.939894</td>\n",
       "      <td>1093.207186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2024-02-03 17:18:05.062702</td>\n",
       "      <td>31.938203</td>\n",
       "      <td>13.883486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.153301</td>\n",
       "      <td>0</td>\n",
       "      <td>1321.409540</td>\n",
       "      <td>1069.939894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2024-02-04 17:18:05.062701</td>\n",
       "      <td>18.024055</td>\n",
       "      <td>7.544061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610703</td>\n",
       "      <td>0</td>\n",
       "      <td>1405.323183</td>\n",
       "      <td>1321.409540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2024-02-05 17:18:05.062700</td>\n",
       "      <td>20.681067</td>\n",
       "      <td>18.820490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533488</td>\n",
       "      <td>0</td>\n",
       "      <td>1001.499120</td>\n",
       "      <td>1405.323183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2024-02-06 17:18:05.062700</td>\n",
       "      <td>16.010132</td>\n",
       "      <td>7.705941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.632498</td>\n",
       "      <td>1</td>\n",
       "      <td>1221.922141</td>\n",
       "      <td>1001.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2024-02-07 17:18:05.062699</td>\n",
       "      <td>18.766455</td>\n",
       "      <td>6.274840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.806554</td>\n",
       "      <td>0</td>\n",
       "      <td>956.412724</td>\n",
       "      <td>1221.922141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2024-02-08 17:18:05.062699</td>\n",
       "      <td>27.948793</td>\n",
       "      <td>23.705246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0</td>\n",
       "      <td>1090.592622</td>\n",
       "      <td>956.412724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2024-02-09 17:18:05.062698</td>\n",
       "      <td>28.661072</td>\n",
       "      <td>10.329865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.290591</td>\n",
       "      <td>0</td>\n",
       "      <td>936.465043</td>\n",
       "      <td>1090.592622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2024-02-10 17:18:05.062697</td>\n",
       "      <td>10.821693</td>\n",
       "      <td>3.575645</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0</td>\n",
       "      <td>1343.336362</td>\n",
       "      <td>936.465043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2024-02-11 17:18:05.062696</td>\n",
       "      <td>21.108560</td>\n",
       "      <td>6.221089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0</td>\n",
       "      <td>1390.698477</td>\n",
       "      <td>1343.336362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2024-02-12 17:18:05.062694</td>\n",
       "      <td>29.451301</td>\n",
       "      <td>5.021463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.493085</td>\n",
       "      <td>0</td>\n",
       "      <td>979.255235</td>\n",
       "      <td>1390.698477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2024-02-13 17:18:05.062670</td>\n",
       "      <td>19.261458</td>\n",
       "      <td>0.438381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.610422</td>\n",
       "      <td>0</td>\n",
       "      <td>880.188828</td>\n",
       "      <td>979.255235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  average_temperature   rainfall  weekend  \\\n",
       "980 2024-01-25 17:18:05.062708            34.130183   1.454065        0   \n",
       "981 2024-01-26 17:18:05.062707            32.353643   9.462859        0   \n",
       "982 2024-01-27 17:18:05.062707            18.816833   0.391470        1   \n",
       "983 2024-01-28 17:18:05.062706            34.533012   2.120477        1   \n",
       "984 2024-01-29 17:18:05.062705            23.057202   2.365705        0   \n",
       "985 2024-01-30 17:18:05.062704            34.810165   3.089005        0   \n",
       "986 2024-01-31 17:18:05.062704            29.208905   3.673292        0   \n",
       "987 2024-02-01 17:18:05.062703            16.428676   4.077782        0   \n",
       "988 2024-02-02 17:18:05.062702            32.067512   2.734454        0   \n",
       "989 2024-02-03 17:18:05.062702            31.938203  13.883486        1   \n",
       "990 2024-02-04 17:18:05.062701            18.024055   7.544061        1   \n",
       "991 2024-02-05 17:18:05.062700            20.681067  18.820490        0   \n",
       "992 2024-02-06 17:18:05.062700            16.010132   7.705941        0   \n",
       "993 2024-02-07 17:18:05.062699            18.766455   6.274840        0   \n",
       "994 2024-02-08 17:18:05.062699            27.948793  23.705246        0   \n",
       "995 2024-02-09 17:18:05.062698            28.661072  10.329865        0   \n",
       "996 2024-02-10 17:18:05.062697            10.821693   3.575645        1   \n",
       "997 2024-02-11 17:18:05.062696            21.108560   6.221089        1   \n",
       "998 2024-02-12 17:18:05.062694            29.451301   5.021463        0   \n",
       "999 2024-02-13 17:18:05.062670            19.261458   0.438381        0   \n",
       "\n",
       "     holiday  price_per_kg  promo       demand  previous_days_demand  \n",
       "980        0      1.449177      0   999.306290           1029.418398  \n",
       "981        0      2.856503      0   842.129427            999.306290  \n",
       "982        0      1.326429      0  1317.616709            842.129427  \n",
       "983        0      0.970131      0  1395.802075           1317.616709  \n",
       "984        0      1.049931      0  1019.486305           1395.802075  \n",
       "985        0      2.035149      0  1002.564672           1019.486305  \n",
       "986        0      2.518098      0  1086.143402           1002.564672  \n",
       "987        0      1.268979      0  1093.207186           1086.143402  \n",
       "988        0      0.762317      0  1069.939894           1093.207186  \n",
       "989        0      1.153301      0  1321.409540           1069.939894  \n",
       "990        0      0.610703      0  1405.323183           1321.409540  \n",
       "991        0      1.533488      0  1001.499120           1405.323183  \n",
       "992        0      1.632498      1  1221.922141           1001.499120  \n",
       "993        0      2.806554      0   956.412724           1221.922141  \n",
       "994        0      0.829464      0  1090.592622            956.412724  \n",
       "995        0      2.290591      0   936.465043           1090.592622  \n",
       "996        0      0.897473      0  1343.336362            936.465043  \n",
       "997        0      1.093864      0  1390.698477           1343.336362  \n",
       "998        0      2.493085      0   979.255235           1390.698477  \n",
       "999        0      2.610422      0   880.188828            979.255235  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def generate_apple_sales_data_with_promo_adjustment(base_demand: int = 1000, n_rows: int = 5000):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for predicting apple sales demand with seasonality and inflation.\n",
    "\n",
    "    This function creates a pandas DataFrame with features relevant to apple sales.\n",
    "    The features include date, average_temperature, rainfall, weekend flag, holiday flag,\n",
    "    promotional flag, price_per_kg, and the previous day's demand. The target variable,\n",
    "    'demand', is generated based on a combination of these features with some added noise.\n",
    "\n",
    "    Args:\n",
    "        base_demand (int, optional): Base demand for apples. Defaults to 1000.\n",
    "        n_rows (int, optional): Number of rows (days) of data to generate. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with features and target variable for apple sales prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> df = generate_apple_sales_data_with_seasonality(base_demand=1200, n_rows=6000)\n",
    "        >>> df.head()\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(9999)\n",
    "\n",
    "    # Create date range\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_rows)]\n",
    "    dates.reverse()\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"average_temperature\": np.random.uniform(10, 35, n_rows),\n",
    "            \"rainfall\": np.random.exponential(5, n_rows),\n",
    "            \"weekend\": [(date.weekday() >= 5) * 1 for date in dates],\n",
    "            \"holiday\": np.random.choice([0, 1], n_rows, p=[0.97, 0.03]),\n",
    "            \"price_per_kg\": np.random.uniform(0.5, 3, n_rows),\n",
    "            \"month\": [date.month for date in dates],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Introduce inflation over time (years)\n",
    "    df[\"inflation_multiplier\"] = 1 + (df[\"date\"].dt.year - df[\"date\"].dt.year.min()) * 0.03\n",
    "\n",
    "    # Incorporate seasonality due to apple harvests\n",
    "    df[\"harvest_effect\"] = np.sin(2 * np.pi * (df[\"month\"] - 3) / 12) + np.sin(\n",
    "        2 * np.pi * (df[\"month\"] - 9) / 12\n",
    "    )\n",
    "\n",
    "    # Modify the price_per_kg based on harvest effect\n",
    "    df[\"price_per_kg\"] = df[\"price_per_kg\"] - df[\"harvest_effect\"] * 0.5\n",
    "\n",
    "    # Adjust promo periods to coincide with periods lagging peak harvest by 1 month\n",
    "    peak_months = [4, 10]  # months following the peak availability\n",
    "    df[\"promo\"] = np.where(\n",
    "        df[\"month\"].isin(peak_months),\n",
    "        1,\n",
    "        np.random.choice([0, 1], n_rows, p=[0.85, 0.15]),\n",
    "    )\n",
    "\n",
    "    # Generate target variable based on features\n",
    "    base_price_effect = -df[\"price_per_kg\"] * 50\n",
    "    seasonality_effect = df[\"harvest_effect\"] * 50\n",
    "    promo_effect = df[\"promo\"] * 200\n",
    "\n",
    "    df[\"demand\"] = (\n",
    "        base_demand\n",
    "        + base_price_effect\n",
    "        + seasonality_effect\n",
    "        + promo_effect\n",
    "        + df[\"weekend\"] * 300\n",
    "        + np.random.normal(0, 50, n_rows)\n",
    "    ) * df[\n",
    "        \"inflation_multiplier\"\n",
    "    ]  # adding random noise\n",
    "\n",
    "    # Add previous day's demand\n",
    "    df[\"previous_days_demand\"] = df[\"demand\"].shift(1)\n",
    "    df[\"previous_days_demand\"].fillna(method=\"bfill\", inplace=True)  # fill the first row\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df.drop(columns=[\"inflation_multiplier\", \"harvest_effect\", \"month\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate the dataset!\n",
    "\n",
    "data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n",
    "\n",
    "data[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date\taverage_temperature\trainfall\tweekend\tholiday\tprice_per_kg\tpromo\tdemand\tprevious_days_demand\n",
    "980\t2023-09-14 11:13:56.948267\t34.130183\t1.454065\t0\t0\t1.449177\t0\t971.802447\t1001.085782\n",
    "981\t2023-09-15 11:13:56.948267\t32.353643\t9.462859\t0\t0\t2.856503\t0\t818.951553\t971.802447\n",
    "982\t2023-09-16 11:13:56.948266\t18.816833\t0.391470\t1\t0\t1.326429\t0\t1281.352029\t818.951553\n",
    "983\t2023-09-17 11:13:56.948265\t34.533012\t2.120477\t1\t0\t0.970131\t0\t1357.385504\t1281.352029\n",
    "984\t2023-09-18 11:13:56.948265\t23.057202\t2.365705\t0\t0\t1.049931\t0\t991.427049\t1357.385504\n",
    "985\t2023-09-19 11:13:56.948264\t34.810165\t3.089005\t0\t0\t2.035149\t0\t974.971149\t991.427049\n",
    "986\t2023-09-20 11:13:56.948263\t29.208905\t3.673292\t0\t0\t2.518098\t0\t1056.249547\t974.971149\n",
    "987\t2023-09-21 11:13:56.948263\t16.428676\t4.077782\t0\t0\t1.268979\t0\t1063.118915\t1056.249547\n",
    "988\t2023-09-22 11:13:56.948262\t32.067512\t2.734454\t0\t0\t0.762317\t0\t1040.492007\t1063.118915\n",
    "989\t2023-09-23 11:13:56.948261\t31.938203\t13.883486\t1\t0\t1.153301\t0\t1285.040470\t1040.492007\n",
    "990\t2023-09-24 11:13:56.948261\t18.024055\t7.544061\t1\t0\t0.610703\t0\t1366.644564\t1285.040470\n",
    "991\t2023-09-25 11:13:56.948260\t20.681067\t18.820490\t0\t0\t1.533488\t0\t973.934924\t1366.644564\n",
    "992\t2023-09-26 11:13:56.948259\t16.010132\t7.705941\t0\t0\t1.632498\t1\t1188.291256\t973.934924\n",
    "993\t2023-09-27 11:13:56.948259\t18.766455\t6.274840\t0\t0\t2.806554\t0\t930.089438\t1188.291256\n",
    "994\t2023-09-28 11:13:56.948258\t27.948793\t23.705246\t0\t0\t0.829464\t0\t1060.576311\t930.089438\n",
    "995\t2023-09-29 11:13:56.948257\t28.661072\t10.329865\t0\t0\t2.290591\t0\t910.690776\t1060.576311\n",
    "996\t2023-09-30 11:13:56.948256\t10.821693\t3.575645\t1\t0\t0.897473\t0\t1306.363801\t910.690776\n",
    "997\t2023-10-01 11:13:56.948256\t21.108560\t6.221089\t1\t0\t1.093864\t1\t1564.422372\t1306.363801\n",
    "998\t2023-10-02 11:13:56.948254\t29.451301\t5.021463\t0\t0\t2.493085\t1\t1164.303256\t1564.422372\n",
    "999\t2023-10-03 11:13:56.948248\t19.261458\t0.438381\t0\t0\t2.610422\t1\t1067.963448\t1164.303256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and log the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re now ready to import our model class and train a RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"Apple_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"apples_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"rf_apples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrehaeberlin/getting_started_mlflow/.venv/lib/python3.10/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target and drop irrelevant date field and target field\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/mlflow/models/signature.py:333: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
    "  input_schema = _infer_schema(input_ex)\n",
    "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
    "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!\n",
    "You’ve just logged your first MLflow model!\n",
    "\n",
    "Navigate to the MLflow UI to see the run that was just created (named “apples_rf_test”, logged to the Experiment “Apple_Models”)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
